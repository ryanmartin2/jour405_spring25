---
title: "HW11: Education Level and Survey Weighting"
author: "Your Name Here"
---

```{r setup, include=FALSE}
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
```

# Introduction

In this assignment, you'll examine how survey weighting affects our understanding of voting intentions across different education levels, using the data we examined in class. You'll calculate both weighted and unweighted statistics, create visualizations, and reflect on the implications for reporting.

## The Data

The nonvoters dataset contains survey responses about voting intentions and behaviors from a national survey. The survey was conducted prior to an election and includes demographic information like education level.

```{r}
# Load the dataset
nonvoters_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/refs/heads/main/nonvoters_data.csv")

# Take a quick look at the data structure
glimpse(nonvoters_data)
```

### Key Variables

- `weight`: Survey weight assigned to each respondent
- `Q21`: Voting intention (1 = Yes, 2 = No, 3 = Unsure/Undecided)
- `educ`: Education level (College, Some college, High school or less)

## Task 1: Education Distribution

First, let's examine the distribution of education levels in our sample. Replace "REPLACE_ME" with the correct variable for education level.

```{r}

education_distribution <- nonvoters_data |>
  count(educ) |>
  mutate(percentage = n / sum(n) * 100) |>
  kable(digits = 1, col.names = c("Education Level", "Count", "Percentage (%)"))

education_distribution
```

## Task 2: Reflection Question

Why might education levels in survey samples often differ from the general population? What factors might cause certain education groups to be over or underrepresented?

Education levels in survey samples can differ from the general population if you don't get a survey sample that's representative enough of the general popultion. Certain education groups can be over or underrepresented dependent on the area you are surveying in and the method for which you are surveying.


## Task 3: Unweighted Analysis by Education

Now, let's calculate unweighted voting intentions by education level. This is what we would report if we didn't apply any weighting to our sample.

```{r}
# Calculate unweighted voting intentions by education
unweighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Count responses
  summarize(count = n(), .groups = "drop_last") |>
  # Calculate percentages
  mutate(total = sum(count),
         percentage = count / total * 100) |>
  ungroup()

# Create a more readable format with voting intentions as columns
unweighted_educ_summary <- unweighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(unweighted_educ_summary, digits = 1, caption = "Unweighted Voting Intentions by Education Level")
```

## Task 4: Reflection Question

Based just on this unweighted analysis, what headline might you write for a news story about education and voting intentions?

College-educated citizens shown to be much more likely to vote in upcoming elections.

## Task 5: Weighted Analysis by Education

Next, let's apply survey weights to see how this changes our results. Instead of just counting responses, we'll sum the weights for each group. Replace "REPLACE_ME" with the appropriate weight variable

```{r weighted-by-education}

weighted_by_education <- nonvoters_data |>
  # Filter out missing values
  filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
  # Group by education and response
  group_by(educ, Q21) |>
  # Sum the weights instead of counting
  summarize(weighted_count = sum(weight), .groups = "drop_last") |>
  # Calculate weighted percentages
  mutate(weighted_total = sum(weighted_count),
         weighted_percentage = weighted_count / weighted_total * 100) |>
  ungroup()

# Create a more readable format
weighted_educ_summary <- weighted_by_education |>
  pivot_wider(
    id_cols = educ,
    names_from = Q21,
    values_from = weighted_percentage,
    names_prefix = "pct_"
  ) |>
  rename(
    "Yes (%)" = pct_1,
    "No (%)" = pct_2,
    "Unsure (%)" = pct_3
  )

kable(weighted_educ_summary, digits = 1, caption = "Weighted Voting Intentions by Education Level")
```

## Task 6: Reflection Questions

1. How did the percentages change after applying weights? Which education group showed the biggest changes?

After applying the weights, the percentage of high school of less category lessened by about 3% to 70.8%, showing the biggest change for any group.

2. Why might the weighted results be considered more accurate than the unweighted results?

Weighted results can be more accurate than the unweighted results because the weighted results can factor in discrepancies in the data between the population and survey sample.

## Task 7: Comparison of Weighted vs. Unweighted Results

Let's create a direct comparison table to see the differences more clearly.

```{r}

comparison <- unweighted_educ_summary |>
  inner_join(weighted_educ_summary, by = "educ", suffix = c("_unweighted", "_weighted")) |>
  mutate(
    # Calculate the differences between weighted and unweighted percentages
    yes_diff = `Yes (%)_weighted` - `Yes (%)_unweighted`,
    no_diff = `No (%)_weighted` - `No (%)_unweighted`,
    unsure_diff = `Unsure (%)_weighted` - `Unsure (%)_unweighted`
  ) |>
  # Select just the columns we want to display
  select(educ, yes_diff, no_diff, unsure_diff) |>
  rename(
    "Education Level" = educ,
    "Yes (% point diff)" = yes_diff,
    "No (% point diff)" = no_diff,
    "Unsure (% point diff)" = unsure_diff
  )

kable(comparison, digits = 1, caption = "Difference Between Weighted and Unweighted Results (percentage points)")
```

## Task 8: Reflection Question

Which education group shows the largest differences between weighted and unweighted results?

High school or less

## Task 9: Visualization

Visualizations can help us see the differences more clearly. Let's create a bar chart comparing weighted and unweighted "Yes" responses by education level. Replace "REPLACE_ME" with the correct variable name

```{r}
educ_viz_data <- bind_rows(
  # Unweighted data
  unweighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses (Q21=1)
    mutate(Type = "Unweighted") |>
    select(Type, educ, percentage),
  
  # Weighted data - 
  weighted_by_education |> 
    filter(Q21 == 1) |>  # Only "Yes" responses
    mutate(
      Type = "Weighted",
      percentage = weighted_percentage
    ) |>
    select(Type, educ, percentage)
)

# Create a grouped bar chart
ggplot(educ_viz_data, 
       aes(x = educ, y = percentage, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(
    title = "Weighted vs. Unweighted 'Yes' Responses by Education",
    subtitle = "Q21: Do you plan to vote in the November election?",
    y = "Percentage (%)",
    x = "Education Level"
  ) +
  scale_fill_manual(values = c("Unweighted" = "#619CFF", "Weighted" = "#F8766D")) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )
```

## Task 10: Reflection Questions

Does the visualization make it easier to see the differences between weighted and unweighted results? Why or why not?

Yes, the visualization makes it easier to see the difference between the weighted and unweighted results because the graph shows the difference in each level of education, displaying the vast difference in high school or less but really showing how same college also has a bit of a difference.

## Task 11: Summary

Based on your analysis of weighted and unweighted results by education level, write a brief (2-3 paragraph) journalistic summary of what you found. You should try to address:

1. How education level relates to voting intentions
2. How weighting affected your understanding of this relationship
3. What this means for interpreting polling results in news reporting

1. We can see here how education levels certainly relate to voting. Based on both the numbers we got back and the visualization, its clear to see how the lower the education level, the less likely the survey respondent is to intentfully vote. Even if a survey respondent showed some college experience, their likelihood to vote increase drastically. 

2. Weighting affected my understanding of this relationship because it gives us a better understanding on where the surveying biases lied. Even without seeing individual respondents, weighting showed us where the survey had more or less respondents in terms of diversity with responses. 

3. For interpreting results in news reporting, its important to understand weighting so we can know more about how a certain poll can represent the actual population. For instance, if a sample in a survey is highly weighed to become more value in data, we can see how that respondent was very highly commodity in the response but may represent that subset of the data with less accuracy than if that subgroup of respondents simply had more respondents. 

## Task 12: Final Reflection Questions

1. Why is it important for journalists to understand survey weighting when reporting on polls?
Its important for journalists to understand survey weighting when reporting so they can have the context behind the numbers they're reporting on and understand that surveys may not actually represent a general public's consensus.

2. How might the differences between weighted and unweighted results affect how you would report on this data?
These differences could affect how we report on data because if you report the unweighted data, you may not be accurately reporting on the population because the unweighted data has a higher likelihood of not correctly articulating the public's voting tendencies.

3. What additional information would you want to know about how the weights were calculated before using this data in a news story?
I'd want to know why the high school or less category was weighed so heavily before I use the data in a news story. Is it only becuase they didn't have enough respondents for that category compared to college education? And if that's the reason, why did pollsters get less "high school or less" respondents than "college" respondents?
